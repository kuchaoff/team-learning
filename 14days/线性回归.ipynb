{"cells":[{"cell_type":"markdown","metadata":{"graffitiCellId":"id_3xxr5fb","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"B116BFDF0D464FF49A85A582357D0B4D","mdEditEnable":false},"source":"# 线性回归"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_ht8ukap","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"8FCA1BC77B7F479BA1398473C2691BB0","mdEditEnable":false},"source":"## 线性回归的基本要素\n\n### 线性回归的一般形式：\n有数据集$\\{(x_1,y_1),(x_2,y_2),...,(x_n,y_n)\\}$,其中,$x_i = (x_{i1};x_{i2};x_{i3};...;x_{id}),y_i\\in R$<br> \n其中n表示变量的数量，d表示每个变量的维度。  \n可以用以下函数来描述y和x之间的关系：\n\n$$\n\\begin{align*}\nf(x) \n&= \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + ... + \\theta_dx_d  \\\\\n&= \\sum_{i=0}^{d}\\theta_ix_i \\\\\n\\end{align*}\n$$\n\n### 损失函数\n在模型训练中，我们需要衡量价格预测值与真实值之间的误差。通常我们会选取一个非负数作为误差，且数值越小表示误差越小。一个常用的选择是平方函数。 它在评估索引为 $i$ 的样本误差的表达式为\n\n\n$$\nl^{(i)}(\\mathbf{w}, b) = \\frac{1}{2} \\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2,\n$$\n\n\n\n$$\nL(\\mathbf{w}, b) =\\frac{1}{n}\\sum_{i=1}^n l^{(i)}(\\mathbf{w}, b) =\\frac{1}{n} \\sum_{i=1}^n \\frac{1}{2}\\left(\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b - y^{(i)}\\right)^2.\n$$\n\n\n### 优化函数 - 随机梯度下降\n当模型和损失函数形式较为简单时，上面的误差最小化问题的解可以直接用公式表达出来。这类解叫作解析解（analytical solution）。本节使用的线性回归和平方误差刚好属于这个范畴。然而，大多数深度学习模型并没有解析解，只能通过优化算法有限次迭代模型参数来尽可能降低损失函数的值。这类解叫作数值解（numerical solution）。\n\n在求数值解的优化算法中，小批量随机梯度下降（mini-batch stochastic gradient descent）在深度学习中被广泛使用。它的算法很简单：先选取一组模型参数的初始值，如随机选取；接下来对参数进行多次迭代，使每次迭代都可能降低损失函数的值。在每次迭代中，先随机均匀采样一个由固定数目训练数据样本所组成的小批量（mini-batch）$\\mathcal{B}$，然后求小批量中数据样本的平均损失有关模型参数的导数（梯度），最后用此结果与预先设定的一个正数的乘积作为模型参数在本次迭代的减小量。   \n\n$$\n(\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\partial_{(\\mathbf{w},b)} l^{(i)}(\\mathbf{w},b)\n$$\n  \n学习率: $\\eta$代表在每次优化中，能够学习的步长的大小    \n批量大小: $|\\mathcal{B}|$是小批量计算中的批量大小batch size   \n\n总结一下，优化函数的有以下两个步骤：\n\n- (i)初始化模型参数，一般来说使用随机初始化；\n- (ii)我们在数据上迭代多次，通过在负梯度方向移动参数来更新每个参数。"},{"metadata":{"id":"3091F9DA73814CD9ADC436D4A734BDC7","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"Let $J(\\theta)$ be the cost fucntion, $\\theta$ be the variable, then the gradient is that\n$$\n\\begin{align*}\n\\frac{\\partial{J(\\theta)}}{\\partial\\theta} \n&= \\frac{\\partial}{\\partial\\theta_j}\\frac{1}{2}\\sum_{i=1}^{n}(f_\\theta(x)^{(i)}-y^{(i)})^2 \\\\\n&= 2*\\frac{1}{2}\\sum_{i=1}^{n}(f_\\theta(x)^{(i)}-y^{(i)})*\\frac{\\partial}{\\partial\\theta_j}(f_\\theta(x)^{(i)}-y^{(i)}) \\\\\n&= \\sum_{i=1}^{n}(f_\\theta(x)^{(i)}-y^{(i)})*\\frac{\\partial}{\\partial\\theta_j}(\\sum_{j=0}^{d}\\theta_jx_j^{(i)}-y^{(i)}))\\\\\n&= \\sum_{i=1}^{n}(f_\\theta(x)^{(i)}-y^{(i)})x_j^{(i)} \\\\\n\\end{align*}\n$$"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_v3gyr0b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"469D697FF90B48B7B0B61AED429EB8D6","mdEditEnable":false},"source":"## 矢量计算\n在模型训练或预测时，我们常常会同时处理多个数据样本并用到矢量计算。在介绍线性回归的矢量计算表达式之前，让我们先考虑对两个向量相加的两种方法。\n\n\n1. 向量相加的一种方法是，将这两个向量按元素逐一做标量加法。\n2. 向量相加的另一种方法是，将这两个向量直接做矢量加法。"},{"cell_type":"code","execution_count":2,"metadata":{"graffitiCellId":"id_bp6luds","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"631AD2C3EA1A431287E30A95D535D877","collapsed":false,"scrolled":false},"outputs":[],"source":"import torch\nimport time\n\n# init variable a, b as 1000 dimension vector\nn = 1000\na = torch.ones(n)\nb = torch.ones(n)\n"},{"cell_type":"code","execution_count":3,"metadata":{"graffitiCellId":"id_xxj5nbf","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"55B0FCA128314322808F46633FA9B944","collapsed":false,"scrolled":false},"outputs":[],"source":"# define a timer class to record time\nclass Timer(object):\n    \"\"\"Record multiple running times.\"\"\"\n    def __init__(self):\n        self.times = []\n        self.start()\n\n    def start(self):\n        # start the timer\n        self.start_time = time.time()\n\n    def stop(self):\n        # stop the timer and record time into a list\n        self.times.append(time.time() - self.start_time)\n        return self.times[-1]\n\n    def avg(self):\n        # calculate the average and return\n        return sum(self.times)/len(self.times)\n\n    def sum(self):\n        # return the sum of recorded time\n        return sum(self.times)"},{"cell_type":"code","execution_count":4,"metadata":{"graffitiCellId":"id_eoz706b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"DF2AACFBA2EA42698CC82C33AF79AEDB","collapsed":false,"scrolled":false},"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"'0.19021 sec'"},"transient":{},"execution_count":4}],"source":"timer = Timer()\nc = torch.zeros(n)\nfor i in range(n):\n    c[i] = a[i] + b[i]\n'%.5f sec' % timer.stop()"},{"cell_type":"code","execution_count":5,"metadata":{"graffitiCellId":"id_a8sw68j","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"6D2503874A514A7590AF8F710B5F325C","collapsed":false,"scrolled":false},"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"'0.00024 sec'"},"transient":{},"execution_count":5}],"source":"timer.start()\nd = a + b\n'%.5f sec' % timer.stop()"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_3y8h3t7","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"84D91561397548D7ACB5FAB71E66AB9B","mdEditEnable":false},"source":"## 线性回归模型从零开始的实现\n\n"},{"cell_type":"code","execution_count":6,"metadata":{"graffitiCellId":"id_3snj2zc","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"B3148881D9514B898929430997FD781C","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"1.3.0\n","name":"stdout"}],"source":"# import packages and modules\n%matplotlib inline\nfrom IPython import display\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport random\n\nprint(torch.__version__)"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_ofruiuq","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"D7C96AC35B12411E8A1530B965CB34E0","mdEditEnable":false},"source":"### 生成数据集\n使用线性模型来生成数据集，生成一个1000个样本的数据集，下面是用来生成数据的线性关系：\n\n$$\n\\mathrm{price} = w_{\\mathrm{area}} \\cdot \\mathrm{area} + w_{\\mathrm{age}} \\cdot \\mathrm{age} + b\n$$\n\n"},{"metadata":{"id":"8CCF0DEECE81418B83187C814C2E9985","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"torch.randn?","execution_count":7},{"cell_type":"code","execution_count":8,"metadata":{"graffitiCellId":"id_h3bosrm","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"1A5F9ED7F99643A3A440960077439F0F","collapsed":false,"scrolled":false},"outputs":[],"source":"# set input feature number \nnum_inputs = 2\n# set example number\nnum_examples = 1000\n\n# set true weight and bias in order to generate corresponded label\ntrue_w = [2, -3.4]\ntrue_b = 4.2\n\n#torch.randn返回指定规模大小的随机数张量，服从标准正态\nfeatures = torch.randn(num_examples, num_inputs,\n                      dtype=torch.float32)\n                      \nlabels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b\nlabels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()),\n                       dtype=torch.float32)"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_gr10soh","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"937B9B59AC2343B58488AAA9B7C11C2A","mdEditEnable":false},"source":"### 使用图像来展示生成的数据"},{"cell_type":"code","execution_count":9,"metadata":{"graffitiCellId":"id_ov2af2a","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"8E2E1E16060241C6A33E4CF1EC65DF1D","collapsed":false,"scrolled":false},"outputs":[{"output_type":"display_data","metadata":{"needs_background":"light"},"data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/rt_upload/8E2E1E16060241C6A33E4CF1EC65DF1D/q5lbec1dwk.png\">"},"transient":{}}],"source":"plt.scatter(features[:, 1].numpy(), labels.numpy(), 1);"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_iivzo2j","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"27981A0FD4054AC39194415A90F313EC","mdEditEnable":false},"source":"### 读取数据集"},{"cell_type":"code","execution_count":10,"metadata":{"graffitiCellId":"id_0tj7eus","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"A6E1419DA00C4ABF8CBF0E0F0B2B9E35","collapsed":false,"scrolled":false},"outputs":[],"source":"#定义根据指定批量大小取数据的迭代生成器\ndef data_iter(batch_size, features, labels):\n    num_examples = len(features)\n    indices = list(range(num_examples))\n    random.shuffle(indices)  # random read 10 samples\n    for i in range(0, num_examples, batch_size):\n        j = torch.LongTensor(indices[i: min(i + batch_size, num_examples)]) # the last time may be not enough for a whole batch\n        yield  features.index_select(0, j), labels.index_select(0, j)"},{"cell_type":"code","execution_count":11,"metadata":{"graffitiCellId":"id_xc0arq3","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"1DA3BC30E43E4F76970F712D89BDBC4D","collapsed":false,"scrolled":true},"outputs":[{"output_type":"stream","text":"1 tensor([[ 0.5704, -2.0905],\n        [-1.6015,  0.8306],\n        [ 1.3263,  1.0075],\n        [-0.6293,  1.8675],\n        [ 1.0948, -0.8146],\n        [-0.7416, -0.2487],\n        [ 0.4685, -0.3066],\n        [ 0.8831, -0.5446],\n        [-2.4263,  0.9963],\n        [ 0.8470,  0.3367]]) \n tensor([12.4479, -1.8203,  3.4314, -3.3950,  9.1680,  3.5457,  6.1658,  7.8206,\n        -4.0401,  4.7491])\n2 tensor([[-2.4191,  1.7469],\n        [-0.5365,  1.3853],\n        [ 0.4494,  0.3427],\n        [ 0.8342,  0.0552],\n        [-0.6565,  0.3223],\n        [-0.6547,  1.6618],\n        [ 0.0141, -0.6019],\n        [ 0.7543, -0.2103],\n        [-0.5425,  1.7227],\n        [ 0.1030,  1.2054]]) \n tensor([-6.5919, -1.5807,  3.9367,  5.6939,  1.7864, -2.7519,  6.2787,  6.4071,\n        -2.7443,  0.2955])\n3 tensor([[ 1.0593, -1.3198],\n        [ 0.6513,  0.7645],\n        [-1.1666, -0.5991],\n        [ 0.9204, -1.4460],\n        [-1.1496, -0.4431],\n        [ 1.0572,  1.6414],\n        [ 0.9567, -1.1844],\n        [-0.5780,  1.5443],\n        [-0.1039, -0.5692],\n        [-1.9578, -0.0165]]) \n tensor([10.7961,  2.9054,  3.9148, 10.9477,  3.3990,  0.7243, 10.1446, -2.1923,\n         5.9423,  0.3506])\n4 tensor([[ 2.1767, -0.1816],\n        [ 0.8394, -0.6380],\n        [-1.0494,  0.8022],\n        [-1.6028, -0.7864],\n        [ 1.5304,  1.0012],\n        [-0.5193, -0.7179],\n        [ 0.0339,  0.3548],\n        [ 0.3538,  0.7726],\n        [ 1.7473,  2.3315],\n        [-0.2229,  0.9702]]) \n tensor([ 9.1887,  8.0555, -0.6364,  3.6685,  3.8601,  5.5878,  3.0660,  2.2724,\n        -0.2277,  0.4590])\n5 tensor([[ 0.7434,  2.4739],\n        [ 0.3026, -0.8819],\n        [-1.5041,  2.4697],\n        [ 0.1699, -0.4113],\n        [-0.3556,  0.2437],\n        [ 1.0365,  0.5564],\n        [ 0.4735, -0.3735],\n        [-0.4385, -0.0328],\n        [-0.6411, -0.8639],\n        [ 0.3344, -1.7107]]) \n tensor([-2.7081,  7.7886, -7.2124,  5.9371,  2.6401,  4.3971,  6.4030,  3.4425,\n         5.8411, 10.6817])\n6 tensor([[ 0.2292,  0.2599],\n        [-2.2628, -0.8155],\n        [ 0.7287,  0.0121],\n        [-0.9992,  0.3194],\n        [ 0.0662, -0.0305],\n        [-1.2244, -1.1826],\n        [ 0.0916,  0.2970],\n        [ 1.1107,  0.9478],\n        [-0.2180, -1.0160],\n        [-0.0579, -2.4269]]) \n tensor([ 3.7563,  2.4421,  5.6089,  1.1031,  4.4257,  5.7841,  3.3713,  3.1921,\n         7.2262, 12.3351])\n7 tensor([[ 0.2004, -0.2454],\n        [ 0.4436, -0.8199],\n        [-0.2844,  1.5446],\n        [-0.9237, -0.1412],\n        [-0.7995,  1.1721],\n        [ 0.0506,  1.0524],\n        [ 0.8699, -0.3534],\n        [ 0.2278,  1.8533],\n        [ 2.1268,  0.0619],\n        [ 1.0656,  0.2732]]) \n tensor([ 5.4340,  7.8667, -1.6298,  2.8535, -1.3978,  0.7185,  7.1487, -1.6352,\n         8.2599,  5.4221])\n8 tensor([[ 0.1417,  1.9690],\n        [-0.2471, -0.5051],\n        [-0.4092, -2.0792],\n        [ 2.6655, -0.0553],\n        [ 0.3953, -1.3000],\n        [-0.6800, -1.0853],\n        [-0.7491,  0.3504],\n        [-0.5035, -0.4145],\n        [ 1.9806,  0.1686],\n        [-0.3458,  0.3497]]) \n tensor([-2.1959,  5.4204, 10.4472,  9.7250,  9.3952,  6.5393,  1.5043,  4.5979,\n         7.5982,  2.3357])\n9 tensor([[-2.2020,  0.3175],\n        [ 0.5435,  0.6112],\n        [ 0.2219,  1.0197],\n        [-1.1553, -1.0477],\n        [ 1.7844, -1.2799],\n        [ 0.7324, -0.5228],\n        [ 0.4347, -0.8535],\n        [-0.3057, -0.0713],\n        [ 1.8961,  1.0462],\n        [-0.3130, -1.3917]]) \n tensor([-1.2852,  3.2318,  1.1844,  5.4616, 12.1245,  7.4565,  7.9457,  3.8330,\n         4.4375,  8.3039])\n10 tensor([[-0.6287,  0.6246],\n        [-0.0853,  0.9568],\n        [ 0.8780, -0.0600],\n        [-0.2653,  0.8733],\n        [ 1.6363, -0.3285],\n        [-2.1728,  0.5164],\n        [-1.2778,  0.9073],\n        [ 1.3866,  2.2586],\n        [-0.6066,  1.6725],\n        [ 0.5889,  0.0780]]) \n tensor([ 0.8196,  0.7803,  6.1695,  0.7106,  8.5893, -1.9009, -1.4443, -0.7140,\n        -2.7079,  5.1113])\n11 tensor([[-0.2694, -1.4777],\n        [ 0.5597,  1.0979],\n        [-0.2033, -0.1826],\n        [-0.6630, -0.3498],\n        [-1.3337,  0.6324],\n        [-2.6362,  0.4741],\n        [-0.8690, -0.6391],\n        [-0.6206,  1.2016],\n        [-1.0172, -0.5952],\n        [-0.8580,  0.4983]]) \n tensor([ 8.6733,  1.5903,  4.4351,  4.0676, -0.6197, -2.6862,  4.6308, -1.1295,\n         4.1903,  0.7887])\n12 tensor([[-1.4412, -0.5045],\n        [-1.5439, -0.5184],\n        [-0.9193,  1.0166],\n        [ 0.7728,  0.7347],\n        [-0.6527, -1.1201],\n        [ 2.0119, -0.9402],\n        [ 0.2823, -1.0867],\n        [-3.3125,  1.1420],\n        [-1.3188,  0.2027],\n        [-1.1282,  0.4010]]) \n tensor([ 3.0350,  2.8632, -1.0924,  3.2362,  6.6999, 11.4356,  8.4628, -6.3154,\n         0.8534,  0.5829])\n13 tensor([[-0.0203,  0.8489],\n        [ 0.1897, -1.0494],\n        [-0.8890, -0.0748],\n        [-0.8982,  0.7347],\n        [ 0.0758,  0.4704],\n        [-0.0804,  0.4852],\n        [-0.9871,  0.6834],\n        [ 1.2621, -0.2062],\n        [ 1.1036, -0.1761],\n        [-1.3429, -1.5229]]) \n tensor([ 1.2737,  8.1561,  2.6838, -0.0878,  2.7523,  2.3916, -0.0902,  7.4385,\n         6.9986,  6.6769])\n14 tensor([[ 0.2499, -0.5731],\n        [-0.9014,  0.7639],\n        [ 0.6798, -1.4118],\n        [-1.0717, -0.4768],\n        [ 0.0845,  0.9282],\n        [ 0.8229, -0.0061],\n        [ 0.1493, -2.1124],\n        [ 0.0618,  0.5599],\n        [-1.5586,  1.6948],\n        [-1.7769, -0.5349]]) \n tensor([ 6.6512, -0.1971, 10.3697,  3.6654,  1.2181,  5.8793, 11.6852,  2.4093,\n        -4.6898,  2.4682])\n15 tensor([[ 0.2120, -0.5916],\n        [-0.5459,  0.1864],\n        [-1.7880, -0.3234],\n        [ 0.6240, -0.3900],\n        [-0.8775,  0.2098],\n        [ 0.0501, -1.0853],\n        [ 0.0620,  0.8342],\n        [ 2.5500, -0.8726],\n        [-2.0537,  2.0717],\n        [ 0.6295, -1.0331]]) \n tensor([ 6.6430,  2.4607,  1.7256,  6.7816,  1.7340,  8.0060,  1.4862, 12.2681,\n        -6.9588,  8.9598])\n16 tensor([[ 1.4732, -0.2569],\n        [ 1.8824, -1.4955],\n        [ 0.9640, -2.2246],\n        [-0.0732, -0.7542],\n        [-2.2327, -0.9791],\n        [ 0.0475, -1.6867],\n        [ 1.5961, -1.4342],\n        [ 0.6260, -0.3137],\n        [-0.2720,  0.0895],\n        [-0.0123, -0.2911]]) \n tensor([ 8.0253, 13.0480, 13.6786,  6.6150,  3.0796, 10.0361, 12.2724,  6.5330,\n         3.3577,  5.1582])\n17 tensor([[ 1.8632,  0.2232],\n        [-0.5328, -1.1973],\n        [ 1.5447,  0.9232],\n        [-0.0349, -0.9043],\n        [-1.4038, -0.8203],\n        [ 0.8198,  1.4475],\n        [-0.2738, -0.3256],\n        [-0.1529, -1.4606],\n        [-0.4191, -0.6745],\n        [-0.4916,  1.1734]]) \n tensor([ 7.1669,  7.2137,  4.1442,  7.2084,  4.1733,  0.9212,  4.7540,  8.8629,\n         5.6617, -0.7716])\n18 tensor([[-0.9025,  3.0194],\n        [ 1.1295, -0.9978],\n        [-0.0687,  0.3050],\n        [-1.5929, -0.8951],\n        [-2.1855, -0.5965],\n        [ 0.0316, -1.2179],\n        [ 1.7214, -1.1491],\n        [-0.0221, -1.0990],\n        [ 0.7133, -1.5295],\n        [-0.3395,  1.8542]]) \n tensor([-7.8833,  9.8499,  3.0146,  4.0607,  1.8508,  8.3938, 11.5581,  7.8972,\n        10.8315, -2.7708])\n19 tensor([[ 0.1071,  0.5007],\n        [ 0.1104, -1.8634],\n        [-0.3192,  0.5862],\n        [ 2.1670, -1.5600],\n        [-1.4415, -1.3420],\n        [ 0.2972, -0.9505],\n        [-0.6442, -1.6117],\n        [ 0.4461,  0.9219],\n        [ 0.9360,  1.6349],\n        [ 1.0297,  0.1164]]) \n tensor([ 2.7034, 10.7608,  1.5602, 13.8326,  5.8943,  8.0364,  8.3825,  1.9605,\n         0.5065,  5.8675])\n20 tensor([[ 1.6226, -0.1978],\n        [ 0.0419, -0.9931],\n        [ 0.0214,  1.2737],\n        [-0.2621, -0.2418],\n        [-0.6922, -0.7599],\n        [-0.6728,  1.2507],\n        [ 0.4284, -0.0871],\n        [ 0.0579, -0.4612],\n        [-0.6361,  1.0932],\n        [ 1.3016, -1.0322]]) \n tensor([ 8.1065,  7.6506, -0.1026,  4.4982,  5.3994, -1.4124,  5.3547,  5.8855,\n        -0.7669, 10.3349])\n21 tensor([[ 0.9050, -0.9475],\n        [ 0.4317, -0.3421],\n        [ 0.0064, -1.4491],\n        [-0.5953, -0.1121],\n        [-0.1412,  2.3965],\n        [-0.6295,  1.2190],\n        [ 0.6273, -0.0731],\n        [ 2.6684, -1.0886],\n        [ 0.1365, -0.7651],\n        [-0.4344, -0.1180]]) \n tensor([ 9.2292,  6.2260,  9.1256,  3.4025, -4.2263, -1.2006,  5.7014, 13.2358,\n         7.0580,  3.7420])\n22 tensor([[-1.0377,  0.1611],\n        [ 1.1442, -1.1688],\n        [-0.9545, -0.1116],\n        [ 1.3238,  0.5542],\n        [ 0.5492,  0.5752],\n        [-0.4836,  2.0621],\n        [-0.5234,  0.0324],\n        [-0.7193, -0.6178],\n        [-0.4498, -0.9457],\n        [-2.0233,  0.5241]]) \n tensor([ 1.5891, 10.4619,  2.6648,  4.9711,  3.3417, -3.7904,  3.0279,  4.8607,\n         6.5131, -1.6244])\n23 tensor([[-0.3632,  0.3819],\n        [ 0.3548,  0.9800],\n        [ 0.2563,  0.8002],\n        [ 0.1819, -0.9856],\n        [ 1.0528, -0.9107],\n        [-0.4022, -1.0667],\n        [-1.0845, -0.1133],\n        [ 1.0666,  0.1555],\n        [ 0.0068,  0.0943],\n        [-0.5084,  1.1146]]) \n tensor([ 2.1867,  1.5910,  1.9883,  7.9270,  9.4023,  7.0286,  2.4158,  5.8045,\n         3.9114, -0.6102])\n24 tensor([[ 0.5371,  0.9280],\n        [-0.5700, -0.1359],\n        [ 0.6075,  3.0090],\n        [-0.8033, -0.1752],\n        [-0.7731, -0.7755],\n        [ 0.9536, -0.2998],\n        [ 0.7972,  0.5282],\n        [ 0.2223, -1.8509],\n        [ 0.4431, -0.5363],\n        [-0.8268,  0.6858]]) \n tensor([ 2.1235,  3.5335, -4.8128,  3.1954,  5.3061,  7.1196,  4.0022, 10.9463,\n         6.8927,  0.2128])\n25 tensor([[ 0.2190, -0.5549],\n        [ 0.3752, -0.0419],\n        [ 0.4288,  0.0785],\n        [-1.9297,  1.7902],\n        [-0.2664,  1.6419],\n        [-0.2583, -0.6293],\n        [-0.2103, -1.0665],\n        [-0.9125,  1.2244],\n        [ 2.3556, -0.6935],\n        [-0.8345,  0.5106]]) \n tensor([ 6.5218,  5.0892,  4.7957, -5.7557, -1.9195,  5.8203,  7.4157, -1.7885,\n        11.2806,  0.8014])\n26 tensor([[ 0.6552,  0.6253],\n        [-0.9523,  1.0318],\n        [-0.2910,  2.1637],\n        [-0.4416, -0.5679],\n        [-0.4682, -1.5761],\n        [ 0.7696, -1.4828],\n        [-0.5868, -0.9846],\n        [-0.7799, -0.7184],\n        [-1.5246, -0.6066],\n        [-1.2619, -0.2611]]) \n tensor([ 3.3828, -1.1986, -3.7436,  5.2511,  8.6197, 10.7780,  6.3724,  5.0840,\n         3.2214,  2.5433])\n27 tensor([[-0.2789, -0.6638],\n        [ 1.3183,  0.7447],\n        [-0.4290,  0.0795],\n        [-0.1494, -0.0073],\n        [ 0.4968,  0.3005],\n        [-0.1411,  1.8918],\n        [ 0.4628,  0.8335],\n        [ 1.5579,  0.8694],\n        [ 0.3542,  0.8469],\n        [ 0.5175,  0.5365]]) \n tensor([ 5.8992,  4.2991,  3.0728,  3.9238,  4.1805, -2.5175,  2.2884,  4.3477,\n         2.0213,  3.3993])\n28 tensor([[-0.1028, -0.0564],\n        [-0.4423,  2.1033],\n        [ 0.4936, -1.6711],\n        [ 2.9771,  1.9603],\n        [-0.1899, -0.6273],\n        [ 1.0869, -0.4059],\n        [ 1.4369,  0.8168],\n        [-0.0762,  0.5793],\n        [-1.5334,  0.9362],\n        [-0.5211,  0.8257]]) \n tensor([ 4.1956, -3.8477, 10.8831,  3.4936,  5.9444,  7.7540,  4.2812,  2.0769,\n        -2.0490,  0.3656])\n29 tensor([[-0.3589, -1.3587],\n        [-0.8280, -1.3331],\n        [-0.5281,  1.8285],\n        [-1.8024,  0.1798],\n        [ 1.8087,  0.3945],\n        [ 1.6883,  0.0807],\n        [-0.8469,  0.2048],\n        [ 0.8343,  0.6199],\n        [ 0.7490,  1.4378],\n        [ 1.0606,  1.3640]]) \n tensor([ 8.1098,  7.0919, -3.0708, -0.0202,  6.4803,  7.3039,  1.8063,  3.7594,\n         0.7968,  1.6719])\n30 tensor([[-0.6503, -0.4122],\n        [ 0.5025, -0.1849],\n        [ 1.0038,  0.9255],\n        [-0.2680, -0.7828],\n        [-0.1325, -0.7518],\n        [-0.2154, -0.5440],\n        [-0.6854, -1.2969],\n        [-0.1330,  1.4012],\n        [-0.9380,  1.9734],\n        [ 0.7808, -0.4872]]) \n tensor([ 4.2956,  5.8338,  3.0655,  6.3336,  6.5116,  5.6304,  7.2461, -0.8256,\n        -4.3982,  7.4172])\n31 tensor([[ 0.9939, -0.9953],\n        [ 0.4832, -1.5794],\n        [-0.3099,  0.1113],\n        [-0.8801,  1.6630],\n        [ 0.3920, -1.5195],\n        [-0.4480,  0.0937],\n        [ 0.8140, -0.5792],\n        [-0.0649,  0.7157],\n        [-1.0883, -0.3323],\n        [ 0.4428, -1.7784]]) \n tensor([ 9.5750, 10.5254,  3.2001, -3.2163, 10.1434,  2.9762,  7.7865,  1.6383,\n         3.1646, 11.1452])\n32 tensor([[ 1.5583,  1.8563],\n        [ 1.2229, -2.1543],\n        [-1.0291, -1.0882],\n        [ 1.5327,  0.6095],\n        [ 1.2642,  0.7241],\n        [ 0.4852,  1.9288],\n        [ 0.3232,  0.9564],\n        [ 1.0522,  0.5746],\n        [ 0.0213,  0.4195],\n        [-0.5292, -0.6738]]) \n tensor([ 1.0010, 13.9659,  5.8310,  5.1650,  4.2684, -1.3771,  1.6009,  4.3446,\n         2.8319,  5.4439])\n33 tensor([[ 1.9880,  0.3416],\n        [-0.5530, -0.4433],\n        [-1.2354,  1.5493],\n        [-0.4210, -0.1547],\n        [-1.0594,  0.7217],\n        [ 0.1169, -0.1105],\n        [-1.1146, -0.9887],\n        [ 0.5586,  0.3744],\n        [ 0.6067, -0.0341],\n        [-0.4462, -0.5171]]) \n tensor([ 7.0164,  4.6030, -3.5377,  3.8972, -0.3708,  4.8183,  5.3332,  4.0339,\n         5.5288,  5.0792])\n34 tensor([[ 1.3764,  2.6734],\n        [ 1.1006,  1.8482],\n        [ 1.1923,  0.4571],\n        [-0.1921, -0.0915],\n        [-0.3944,  1.1289],\n        [ 0.3483, -0.3751],\n        [-1.3896, -0.9664],\n        [-0.0431,  0.0724],\n        [ 0.6612, -0.3737],\n        [ 0.9458,  0.9029]]) \n tensor([-2.1338,  0.1197,  5.0352,  4.1280, -0.4391,  6.1724,  4.7044,  3.8577,\n         6.8078,  3.0100])\n35 tensor([[-0.2733,  1.4887],\n        [ 0.0274, -0.4078],\n        [-0.3640, -0.6092],\n        [ 0.6085, -0.3325],\n        [ 0.3251, -0.8025],\n        [ 0.7387,  0.3359],\n        [-0.5341,  1.0513],\n        [ 1.1465,  0.4086],\n        [-0.9968,  1.4283],\n        [-0.3919, -1.7406]]) \n tensor([-1.4077,  5.6583,  5.5414,  6.5431,  7.5757,  4.5390, -0.4398,  5.1020,\n        -2.6344,  9.3324])\n36 tensor([[-1.2552, -2.5022],\n        [-2.0247, -0.1415],\n        [ 0.0158,  1.1080],\n        [ 1.5611, -1.3899],\n        [-0.2660,  1.2085],\n        [ 0.2663,  0.4403],\n        [-1.0494, -1.1318],\n        [ 0.3125, -0.3930],\n        [ 2.0510, -0.4091],\n        [-0.2738, -0.0346]]) \n tensor([10.2017,  0.6183,  0.4729, 12.0356, -0.4289,  3.2376,  5.9554,  6.1501,\n         9.6955,  3.7661])\n37 tensor([[-0.9289,  1.2571],\n        [-1.5233, -0.2699],\n        [-1.3243,  0.8890],\n        [ 1.6821, -0.6990],\n        [ 0.5418,  1.6694],\n        [-1.2641, -1.6272],\n        [ 1.5455,  0.5923],\n        [-0.0230, -0.1374],\n        [ 0.6209, -0.6596],\n        [-1.1549,  1.2574]]) \n tensor([-1.9227,  2.0750, -1.4663,  9.9416, -0.3872,  7.2036,  5.2685,  4.6123,\n         7.6750, -2.4044])\n38 tensor([[ 1.1974,  1.3208],\n        [ 1.1502,  0.5170],\n        [ 0.6653,  0.2304],\n        [-0.2175, -0.6871],\n        [ 2.4881,  0.0881],\n        [-0.8113,  0.2265],\n        [ 1.3241, -0.3423],\n        [-0.0399,  0.1723],\n        [ 1.5491,  0.0253],\n        [ 0.4335, -0.4920]]) \n tensor([2.0925, 4.7478, 4.7342, 6.0940, 8.8737, 1.8047, 8.0097, 3.5419, 7.2206,\n        6.7164])\n39 tensor([[ 0.0502,  1.4295],\n        [-0.2505,  1.6539],\n        [-1.1718,  1.4469],\n        [-2.6211,  1.1538],\n        [ 0.0640, -0.8038],\n        [ 0.7922, -0.3470],\n        [ 1.8583, -1.4748],\n        [ 3.4698, -1.4988],\n        [-1.4352,  0.2916],\n        [-1.5833,  1.0962]]) \n tensor([-0.5519, -1.9273, -3.0682, -4.9537,  7.0657,  6.9713, 12.9218, 16.2234,\n         0.3513, -2.6879])\n40 tensor([[ 1.4700, -1.0621],\n        [-0.2582, -1.1642],\n        [ 0.0406,  1.5076],\n        [-0.1201,  0.6057],\n        [ 1.4376,  1.2102],\n        [ 2.4035,  0.6939],\n        [-0.8808, -1.1616],\n        [-0.4590, -1.9055],\n        [-0.5407, -0.4244],\n        [ 0.3153,  0.3099]]) \n tensor([10.7541,  7.6518, -0.8373,  1.8912,  2.9492,  6.6412,  6.3773,  9.7634,\n         4.5684,  3.7820])\n41 tensor([[-1.1140, -1.5321],\n        [ 1.5225, -0.5807],\n        [ 0.5369,  1.2484],\n        [ 1.5296, -1.0476],\n        [-1.3843,  0.5427],\n        [-0.0442,  0.0637],\n        [-0.4225, -0.4257],\n        [-0.2774, -1.0783],\n        [-1.4968,  0.0130],\n        [-0.5897,  0.6808]]) \n tensor([ 7.2036,  9.2019,  1.0222, 10.8169, -0.4155,  3.9068,  4.8105,  7.3258,\n         1.1631,  0.7041])\n42 tensor([[ 0.8492,  1.3477],\n        [-0.3609,  0.0228],\n        [ 0.4907, -1.3674],\n        [-0.1633, -0.5832],\n        [ 1.0616, -0.4522],\n        [-0.6115,  1.1348],\n        [-1.8269,  0.9830],\n        [ 0.1207, -0.0197],\n        [ 2.0139,  1.6628],\n        [ 0.8791, -0.5396]]) \n tensor([ 1.3220,  3.4066,  9.8402,  5.8387,  7.8575, -0.8834, -2.8035,  4.5104,\n         2.5885,  7.8059])\n43 tensor([[ 9.8894e-01,  4.2818e-01],\n        [ 1.1480e+00,  2.3207e+00],\n        [ 1.2326e+00,  6.8572e-02],\n        [ 1.0008e+00, -2.2776e-03],\n        [-3.3829e-01, -1.3029e+00],\n        [ 3.9044e-01, -5.9900e-01],\n        [-1.2214e+00,  2.2162e+00],\n        [-1.4204e+00,  4.4657e-01],\n        [-1.9520e+00,  1.2555e+00],\n        [ 4.6051e-02, -3.5037e-01]]) \n tensor([ 4.7257, -1.3793,  6.4096,  6.2034,  7.9431,  7.0148, -5.7588, -0.1596,\n        -3.9672,  5.4733])\n44 tensor([[-0.8503, -0.3246],\n        [-0.6174,  1.2376],\n        [ 0.0562,  0.5010],\n        [-0.5267,  1.6163],\n        [-0.3516,  0.4974],\n        [ 0.6124, -0.6414],\n        [ 0.6974,  1.7709],\n        [-0.2589, -0.2776],\n        [-0.2807, -0.7597],\n        [ 1.3961,  0.9262]]) \n tensor([ 3.6138, -1.2370,  2.5993, -2.3491,  1.8059,  7.6010, -0.4197,  4.6353,\n         6.2235,  3.8364])\n45 tensor([[-0.9805, -1.3305],\n        [ 0.2208, -0.1443],\n        [ 2.8582,  1.1722],\n        [-0.1576,  1.2317],\n        [ 1.5606,  1.5700],\n        [-1.4619,  0.4095],\n        [-1.4150,  2.1799],\n        [-0.5951, -0.4655],\n        [ 1.1010,  1.0754],\n        [-0.6700,  0.1081]]) \n tensor([ 6.7649,  5.1170,  5.9287, -0.3175,  1.9746, -0.1104, -6.0348,  4.5993,\n         2.7343,  2.4975])\n46 tensor([[-0.6009, -0.9546],\n        [ 0.0666,  0.7892],\n        [ 0.9477, -0.9946],\n        [-0.0397, -0.0522],\n        [-3.0722,  0.2714],\n        [ 1.0027, -1.1552],\n        [ 0.4697,  1.5747],\n        [ 0.7477, -0.9368],\n        [-0.0089,  0.2890],\n        [ 2.6991,  1.9515]]) \n tensor([ 6.2530,  1.6473,  9.5096,  4.2908, -2.8655, 10.1355, -0.2237,  8.8751,\n         3.2025,  2.9637])\n47 tensor([[ 0.5283,  0.4904],\n        [-1.3085,  0.2706],\n        [ 1.1830,  0.0533],\n        [-0.3597,  1.3104],\n        [ 0.1206, -1.3700],\n        [-1.3492, -1.2628],\n        [-0.5532, -1.1083],\n        [ 2.2040, -1.8862],\n        [ 0.8989,  1.7535],\n        [ 0.0997, -0.5675]]) \n tensor([ 3.5756,  0.6427,  6.3857, -0.9717,  9.0916,  5.8043,  6.8787, 15.0148,\n         0.0313,  6.3213])\n48 tensor([[-1.0824,  0.2368],\n        [-0.1142, -1.9770],\n        [ 0.5718,  0.7461],\n        [ 0.4554,  0.9819],\n        [ 2.1940,  1.6569],\n        [ 1.8959,  0.2281],\n        [ 1.8908, -0.4471],\n        [ 3.7118,  0.5324],\n        [-0.4466,  0.4664],\n        [ 2.0283,  1.0096]]) \n tensor([ 1.2055, 10.6900,  2.7954,  1.7717,  2.9558,  7.2157,  9.5043,  9.8150,\n         1.7109,  4.8135])\n49 tensor([[-0.2466,  0.5987],\n        [-0.3041, -0.5390],\n        [ 0.0975,  0.8782],\n        [-0.4135, -1.0701],\n        [ 0.4380, -1.1918],\n        [ 1.1754, -2.0043],\n        [ 0.8385,  2.1726],\n        [-0.4640, -0.8348],\n        [-0.4994, -1.1309],\n        [ 0.8309,  1.3898]]) \n tensor([ 1.6717,  5.4285,  1.3890,  7.0049,  9.1156, 13.3854, -1.5124,  6.1040,\n         7.0558,  1.1454])\n50 tensor([[-1.5423, -0.2938],\n        [-0.1041,  0.8924],\n        [-0.4539, -0.5046],\n        [-2.0482,  0.1278],\n        [ 2.0841, -1.4727],\n        [ 0.3808,  0.3223],\n        [ 0.9943, -0.1613],\n        [-0.1818, -1.3473],\n        [-0.9791, -1.4371],\n        [-0.0307, -1.4389]]) \n tensor([ 2.1113,  0.9633,  4.9992, -0.3307, 13.3822,  3.8579,  6.7423,  8.4180,\n         7.1297,  9.0405])\n51 tensor([[ 0.1490, -0.3394],\n        [ 0.7784,  0.3340],\n        [-0.2723, -0.0557],\n        [-0.8949,  0.7864],\n        [-0.7975,  0.4881],\n        [ 0.2291, -0.6704],\n        [ 0.4048, -1.5502],\n        [-1.6165,  1.0931],\n        [-0.2083,  0.9994],\n        [-1.7654,  0.5800]]) \n tensor([ 5.6442,  4.6345,  3.8311, -0.2712,  0.9487,  6.9252, 10.2763, -2.7420,\n         0.3804, -1.3005])\n52 tensor([[-0.1644, -1.8758],\n        [-0.2263,  2.1795],\n        [-0.7378, -0.4036],\n        [-1.0079,  0.5194],\n        [-2.2831,  1.1955],\n        [-0.2640,  0.9111],\n        [ 0.6203,  0.5919],\n        [ 0.1275, -0.6274],\n        [-1.2477, -0.5963],\n        [ 1.0157, -0.4716]]) \n tensor([10.2671, -3.6488,  4.1072,  0.4149, -4.4233,  0.5703,  3.4314,  6.5716,\n         3.7267,  7.8230])\n53 tensor([[-0.4820,  0.7542],\n        [ 0.4613,  0.6309],\n        [-0.2409,  0.3078],\n        [ 1.4098,  0.4986],\n        [-1.0060,  0.0853],\n        [-0.4770, -0.3979],\n        [ 0.7614, -0.7921],\n        [ 1.4952, -0.3561],\n        [ 0.6456, -3.4647],\n        [-0.1776, -0.2054]]) \n tensor([ 0.6887,  2.9947,  2.6628,  5.3086,  1.8890,  4.6046,  8.4152,  8.4078,\n        17.2683,  4.5368])\n54 tensor([[-0.4219,  0.5289],\n        [ 0.2949, -0.2044],\n        [-1.0614,  0.4599],\n        [-0.8184, -0.5402],\n        [ 0.3883,  0.9559],\n        [-1.6058,  0.1142],\n        [ 0.4703,  0.0215],\n        [ 1.0111,  0.4902],\n        [-0.7823, -0.0855],\n        [-0.3104, -1.5045]]) \n tensor([1.5645, 5.4824, 0.5117, 4.4018, 1.7372, 0.5902, 5.0816, 4.5402, 2.9431,\n        8.7017])\n55 tensor([[-0.1055, -0.7523],\n        [-1.6023,  0.2455],\n        [ 2.5046,  1.5290],\n        [-0.1329,  1.6263],\n        [-0.8959, -1.5722],\n        [ 0.8519, -0.2964],\n        [-0.5176,  0.5955],\n        [ 0.9316, -0.0231],\n        [ 1.2746, -1.6041],\n        [-0.5832, -0.3348]]) \n tensor([ 6.5558,  0.1492,  4.0190, -1.5923,  7.7406,  6.9174,  1.1522,  6.1480,\n        12.2053,  4.1640])\n56 tensor([[ 0.8852, -0.2748],\n        [ 0.6809, -0.2711],\n        [ 0.4839,  1.2353],\n        [ 1.2041, -0.7885],\n        [ 0.0253, -1.3179],\n        [ 0.8700,  0.7222],\n        [-0.6270,  0.6162],\n        [-0.5643, -0.9600],\n        [ 0.8466, -1.1706],\n        [-2.2322, -0.6946]]) \n tensor([6.8948, 6.4845, 0.9624, 9.2748, 8.7189, 3.4743, 0.8455, 6.3218, 9.8878,\n        2.1226])\n57 tensor([[-1.1843,  0.1269],\n        [-1.5955,  0.6644],\n        [-0.0137, -0.4490],\n        [ 0.9172,  0.9454],\n        [ 0.3660, -1.5315],\n        [-2.4992, -0.6499],\n        [-0.0397, -1.1221],\n        [ 0.6920, -0.8033],\n        [-0.0801,  0.1511],\n        [-0.0065,  0.3504]]) \n tensor([ 1.4136, -1.2499,  5.7036,  2.8301, 10.1482,  1.4002,  7.9335,  8.3166,\n         3.5307,  2.9971])\n58 tensor([[-1.3781, -0.2279],\n        [ 1.1009,  0.9972],\n        [ 0.3513, -0.8136],\n        [ 0.3069, -0.9163],\n        [ 0.7862, -1.1042],\n        [ 1.2762, -1.1558],\n        [ 1.7041, -0.5366],\n        [ 0.4173, -0.6396],\n        [-0.9059,  0.1875],\n        [-0.5102, -1.4338]]) \n tensor([ 2.2212,  2.9932,  7.6632,  7.9242,  9.5194, 10.6724,  9.4489,  7.2008,\n         1.7616,  8.0542])\n59 tensor([[-1.5213, -0.5422],\n        [ 0.3021, -0.4827],\n        [ 1.6600,  0.3696],\n        [ 0.4404, -0.4380],\n        [-0.5187, -0.5118],\n        [-1.9245, -1.4734],\n        [-0.6669, -0.7313],\n        [-0.4641, -0.0676],\n        [ 1.1827, -1.3845],\n        [ 0.2749,  0.1982]]) \n tensor([ 3.0219,  6.4564,  6.2682,  6.5723,  4.9156,  5.3553,  5.3481,  3.5112,\n        11.2626,  4.0771])\n60 tensor([[ 0.0359,  1.5472],\n        [ 0.1814, -0.9826],\n        [ 0.3447,  0.8128],\n        [ 1.0610,  0.7023],\n        [-0.2162,  0.3002],\n        [ 2.5740,  2.2707],\n        [ 1.1655,  0.8742],\n        [-0.6560,  0.6114],\n        [-0.8431,  0.3757],\n        [ 0.9620,  0.2148]]) \n tensor([-0.9826,  7.8903,  2.1279,  3.9109,  2.7692,  1.6084,  3.5715,  0.8037,\n         1.2325,  5.3851])\n61 tensor([[ 0.8084, -0.2478],\n        [-0.0054,  1.1521],\n        [ 0.4810, -0.2351],\n        [-1.5498,  0.7120],\n        [-1.2644,  0.1496],\n        [-0.8081,  1.2844],\n        [ 1.0834, -0.0239],\n        [-0.8518,  2.1077],\n        [ 0.7362,  1.3362],\n        [-2.6940, -0.7575]]) \n tensor([ 6.6516,  0.2755,  5.9670, -1.3237,  1.1552, -1.7929,  6.4448, -4.6724,\n         1.1448,  1.3763])\n62 tensor([[ 0.3004, -0.3772],\n        [ 0.2741,  0.6897],\n        [-0.8364, -0.7579],\n        [-0.4854, -0.2884],\n        [-0.2038, -0.0965],\n        [ 0.1902, -0.0563],\n        [-0.4006, -0.3028],\n        [ 0.2305, -0.7150],\n        [-1.7247,  0.6291],\n        [ 0.4185,  0.9121]]) \n tensor([ 6.0871,  2.4072,  5.1126,  4.2175,  4.1329,  4.7937,  4.4320,  7.0872,\n        -1.3916,  1.9365])\n63 tensor([[-0.0934,  1.6580],\n        [-0.8396, -1.1007],\n        [-1.1017,  0.2750],\n        [-0.9688,  0.0074],\n        [ 0.1116, -2.0965],\n        [-1.0257, -1.0427],\n        [-1.3770,  1.3100],\n        [-0.2211,  0.3182],\n        [-2.2189,  0.7209],\n        [ 0.4918, -0.4546]]) \n tensor([-1.6389,  6.2775,  1.0639,  2.2337, 11.5473,  5.7053, -3.0169,  2.6941,\n        -2.6953,  6.7435])\n64 tensor([[ 1.6079, -0.5170],\n        [-0.8319, -0.6743],\n        [-1.3348,  0.2157],\n        [ 0.1984,  0.8683],\n        [-0.3487,  0.9209],\n        [-0.3018,  0.1084],\n        [-0.4661, -1.0093],\n        [-0.5140, -0.3881],\n        [ 1.3518, -0.2857],\n        [-0.0235, -0.1848]]) \n tensor([9.1876, 4.8276, 0.8125, 1.6497, 0.3773, 3.2357, 6.6769, 4.5063, 7.8831,\n        4.7900])\n65 tensor([[ 0.8961,  0.9530],\n        [-0.8307, -1.2115],\n        [-0.6023,  0.7915],\n        [ 0.0256, -0.9463],\n        [ 0.6993,  0.3494],\n        [ 1.9783, -0.1066],\n        [ 0.5721,  1.7977],\n        [ 2.2414, -0.3206],\n        [-0.4771,  0.6453],\n        [ 0.1061, -0.0903]]) \n tensor([ 2.7586,  6.6511,  0.3129,  7.4871,  4.4160,  8.5103, -0.7656,  9.7860,\n         1.0629,  4.7151])\n66 tensor([[ 0.2086,  0.0716],\n        [-0.0202, -0.9045],\n        [ 1.3298, -0.2314],\n        [-0.8219,  0.1518],\n        [ 1.3120,  0.6457],\n        [-0.5517,  0.3059],\n        [-1.3631,  0.2864],\n        [ 1.2026,  0.7973],\n        [ 0.5525,  1.5981],\n        [ 0.7680, -1.5453]]) \n tensor([ 4.3742,  7.2423,  7.6449,  2.0354,  4.6309,  2.0614,  0.4962,  3.8809,\n        -0.1331, 10.9942])\n67 tensor([[ 0.6613,  0.7522],\n        [-0.0288, -0.6239],\n        [ 0.6532, -0.2050],\n        [-0.4151,  0.3746],\n        [-1.1921, -2.5912],\n        [-0.2339,  0.0339],\n        [ 0.3290,  0.9819],\n        [ 2.0503,  0.5044],\n        [-0.2213, -0.7615],\n        [ 0.8407, -0.1851]]) \n tensor([ 2.9439,  6.2621,  6.2024,  2.1029, 10.6447,  3.6177,  1.5143,  6.5917,\n         6.3570,  6.5084])\n68 tensor([[-0.2858,  1.3663],\n        [ 0.1641, -0.4194],\n        [-1.1156,  1.6780],\n        [ 0.2915, -0.6687],\n        [ 0.3660,  2.3761],\n        [-2.0427,  1.1801],\n        [-0.3743, -1.2194],\n        [ 0.2557, -0.9714],\n        [ 0.7566,  0.6631],\n        [-0.4037,  1.1772]]) \n tensor([-1.0262,  5.9608, -3.7468,  7.0505, -3.1468, -3.9129,  7.6092,  8.0213,\n         3.4526, -0.5966])\n69 tensor([[-0.1192,  0.1602],\n        [ 1.6201, -1.0825],\n        [-0.3034, -1.0429],\n        [ 0.7574,  1.8696],\n        [-0.5241,  0.4880],\n        [-1.4046, -1.3301],\n        [ 0.1606,  1.2677],\n        [-0.1906,  0.1956],\n        [ 0.6258,  0.5677],\n        [-1.0895,  0.9353]]) \n tensor([ 3.4097, 11.1223,  7.1401, -0.6406,  1.5062,  5.9113,  0.2055,  3.1415,\n         3.5226, -1.1610])\n70 tensor([[ 1.5054,  0.9252],\n        [ 0.2988,  0.2573],\n        [ 1.4348,  0.8319],\n        [-0.3172, -0.4100],\n        [-0.0294, -1.2895],\n        [-0.7571, -0.1940],\n        [-0.7988,  1.8332],\n        [-0.9027, -0.5703],\n        [-0.8680, -0.1656],\n        [ 1.9248, -1.2452]]) \n tensor([ 4.0620,  3.9234,  4.2451,  4.9758,  8.5310,  3.3342, -3.6346,  4.3333,\n         3.0007, 12.2747])\n71 tensor([[ 1.0804,  1.9084],\n        [-0.0464,  0.4060],\n        [ 0.0245, -0.5809],\n        [ 1.4287, -0.0385],\n        [-1.0161, -2.3728],\n        [ 0.4890,  0.7050],\n        [ 0.2590, -1.0142],\n        [-0.3657,  1.4090],\n        [ 0.0150, -0.4114],\n        [-1.1454, -0.8832]]) \n tensor([-0.1138,  2.7279,  6.2282,  7.1905, 10.2437,  2.7854,  8.1750, -1.3370,\n         5.6252,  4.9083])\n72 tensor([[-1.2268, -0.1660],\n        [-0.9915, -1.1098],\n        [-0.1460,  0.0310],\n        [-1.3079,  1.4877],\n        [ 0.5333, -1.2930],\n        [ 0.2848, -1.0550],\n        [ 1.2953,  0.1743],\n        [ 0.4271,  0.1749],\n        [ 0.2260, -0.3416],\n        [-0.2872, -0.7898]]) \n tensor([ 2.2923,  6.0029,  3.8001, -3.4629,  9.6526,  8.3450,  6.1948,  4.4735,\n         5.8126,  6.3150])\n73 tensor([[ 1.0545,  0.1155],\n        [ 1.2111,  0.2410],\n        [ 0.2821, -2.6270],\n        [ 1.1486,  2.1568],\n        [-0.6704, -2.0924],\n        [-0.3907, -1.6684],\n        [ 0.3333,  0.1932],\n        [-0.5681,  2.2629],\n        [-0.8326, -0.3696],\n        [ 0.1229, -0.7508]]) \n tensor([ 5.9136,  5.7920, 13.7081, -0.8414,  9.9817,  9.1036,  4.1894, -4.6278,\n         3.8096,  6.9919])\n74 tensor([[-0.5123,  0.6953],\n        [ 1.6955, -0.5613],\n        [ 2.3787,  0.0623],\n        [-0.9600, -1.3744],\n        [ 0.3320,  0.3116],\n        [ 1.7593,  1.4125],\n        [-0.8144,  0.8068],\n        [ 0.1358, -1.4996],\n        [ 0.1710,  1.1347],\n        [ 0.5905, -0.0531]]) \n tensor([ 0.8101,  9.4763,  8.7593,  6.9463,  3.8063,  2.9254, -0.1503,  9.5695,\n         0.7040,  5.5577])\n75 tensor([[-0.0029, -0.9612],\n        [ 2.2135, -1.7558],\n        [ 1.3442,  0.4267],\n        [-0.2778,  2.2064],\n        [-0.4764, -0.5239],\n        [-0.4503, -1.6258],\n        [-1.4811, -1.4338],\n        [ 0.6249,  0.1168],\n        [-1.2206,  1.4461],\n        [-0.4231, -1.2246]]) \n tensor([ 7.4752, 14.6093,  5.4394, -3.8608,  5.0282,  8.8312,  6.1086,  5.0425,\n        -3.1597,  7.5125])\n76 tensor([[ 1.0738,  0.0307],\n        [-0.5142,  0.4842],\n        [ 0.7758,  1.4284],\n        [-0.8517,  0.7532],\n        [-0.7336,  0.3009],\n        [-0.8182, -0.0617],\n        [-1.0424,  0.3691],\n        [ 1.8976,  0.1317],\n        [-0.1070,  1.4965],\n        [-1.4002, -0.6125]]) \n tensor([ 6.2427,  1.5285,  0.8821, -0.0637,  1.7140,  2.7615,  0.8450,  7.5377,\n        -1.0935,  3.4514])\n77 tensor([[-0.1145,  0.3980],\n        [-0.7569, -0.0183],\n        [-1.8878,  0.6451],\n        [-1.7829, -0.4806],\n        [-0.4481, -0.4207],\n        [ 2.1016, -0.9726],\n        [ 0.9371, -0.9457],\n        [ 0.2065, -0.4841],\n        [ 0.1420,  1.4835],\n        [-0.0486, -0.0449]]) \n tensor([ 2.6139,  2.7668, -1.7535,  2.2759,  4.7315, 11.7147,  9.2962,  6.2467,\n        -0.5587,  4.2757])\n78 tensor([[ 0.7598, -1.2093],\n        [ 0.6734,  0.1047],\n        [-1.7872, -0.5378],\n        [ 1.2678, -1.2449],\n        [-0.1811,  2.0626],\n        [-1.6278, -0.6999],\n        [ 1.9260,  0.1985],\n        [ 0.2578, -1.2193],\n        [-0.5483,  1.1790],\n        [-0.6083, -0.6767]]) \n tensor([ 9.8284,  5.1940,  2.4494, 10.9538, -3.1796,  3.3239,  7.3562,  8.8786,\n        -0.8946,  5.2902])\n79 tensor([[ 0.2832,  2.1685],\n        [ 2.5520, -1.1023],\n        [-0.8270,  0.1486],\n        [-1.6667, -1.8688],\n        [-1.9769,  1.9489],\n        [ 0.4398,  2.3143],\n        [ 0.5529,  0.4903],\n        [ 1.4950,  0.2896],\n        [-0.4687, -0.7371],\n        [ 0.2361,  0.0546]]) \n tensor([-2.6096, 13.0618,  2.0340,  7.2091, -6.3808, -2.7956,  3.6362,  6.2041,\n         5.7691,  4.4796])\n80 tensor([[-0.7101,  0.0500],\n        [ 0.9988,  0.3355],\n        [ 0.4336,  1.8121],\n        [-0.9576, -1.0594],\n        [-0.0506, -0.5458],\n        [ 0.6572, -1.0968],\n        [ 1.1160, -1.3855],\n        [-1.1226,  1.1870],\n        [-0.7561, -0.6115],\n        [-0.3438, -1.5367]]) \n tensor([ 2.6181,  5.0398, -1.0816,  5.8781,  5.9636,  9.2283, 11.1352, -2.0849,\n         4.7673,  8.7387])\n81 tensor([[ 0.6064,  1.1446],\n        [-1.2417, -0.4486],\n        [-0.5403, -0.9671],\n        [-0.2662, -0.3192],\n        [ 0.3721, -0.2037],\n        [ 1.3078,  0.9432],\n        [-1.5918, -1.9022],\n        [ 1.3249, -0.2626],\n        [ 2.3389,  0.8980],\n        [ 0.1319,  0.5666]]) \n tensor([1.5387, 3.2221, 6.4149, 4.7688, 5.6347, 3.6068, 7.4914, 7.7359, 5.8231,\n        2.5316])\n82 tensor([[ 0.4971,  1.1554],\n        [ 0.5242,  0.6258],\n        [-0.9769, -0.0553],\n        [ 0.8552,  0.9107],\n        [ 0.6643,  0.7060],\n        [ 0.0262, -0.4771],\n        [ 1.5132, -0.4274],\n        [-1.4072,  0.5724],\n        [-0.0052,  0.5827],\n        [-0.2225, -1.5754]]) \n tensor([ 1.2802,  3.1254,  2.4492,  2.8216,  3.1475,  5.8718,  8.6803, -0.5606,\n         2.1965,  9.1231])\n83 tensor([[-0.2217, -0.9066],\n        [ 0.6409,  1.0737],\n        [-1.6368, -1.2042],\n        [ 0.5377, -0.1587],\n        [ 0.8526, -0.4200],\n        [ 1.2096,  0.6662],\n        [ 0.5078,  0.2538],\n        [-1.0606, -0.8322],\n        [ 0.0695,  0.4255],\n        [-0.3122, -1.6680]]) \n tensor([6.8354, 1.8376, 5.0215, 5.8178, 7.3256, 4.3643, 4.3516, 4.8999, 2.9018,\n        9.2524])\n84 tensor([[-2.0929, -0.1185],\n        [ 0.5176, -0.9323],\n        [ 1.4321,  0.2845],\n        [-1.2623, -0.0987],\n        [ 1.1109,  0.4116],\n        [ 1.3474,  0.6878],\n        [ 1.4764, -0.9040],\n        [-0.1322,  0.6073],\n        [ 0.4617,  1.2118],\n        [-1.9595, -1.6943]]) \n tensor([ 0.4260,  8.4109,  6.0992,  2.0313,  5.0201,  4.5441, 10.2235,  1.8555,\n         1.0116,  6.0379])\n85 tensor([[-0.2895,  0.2329],\n        [ 0.4925, -1.3539],\n        [-1.4319, -0.7290],\n        [ 0.6963, -1.8990],\n        [-0.6765, -0.4365],\n        [-0.7972,  1.5793],\n        [ 1.9320, -0.7742],\n        [-0.1377,  0.8079],\n        [-0.3265, -0.8219],\n        [-1.3076,  0.6968]]) \n tensor([ 2.8366,  9.7864,  3.7981, 12.0645,  4.3269, -2.7573, 10.6985,  1.1731,\n         6.3425, -0.7957])\n86 tensor([[ 1.0785,  0.2433],\n        [ 0.7765, -1.4377],\n        [-1.2274,  1.4215],\n        [ 1.9694, -1.7553],\n        [-0.0290, -1.0708],\n        [ 1.9291, -0.1153],\n        [-1.0551,  1.0470],\n        [-0.5343, -0.6342],\n        [ 0.1340, -0.7927],\n        [-0.2785, -0.5750]]) \n tensor([ 5.5364, 10.6291, -3.0892, 14.1185,  7.7859,  8.4384, -1.4726,  5.2919,\n         7.1735,  5.5844])\n87 tensor([[-0.7777,  0.5893],\n        [-0.1302, -0.1193],\n        [-0.4337, -0.1606],\n        [-0.7537,  2.2930],\n        [-0.5378, -0.3793],\n        [-1.7383,  0.7447],\n        [ 0.9943,  0.7033],\n        [ 0.1355,  0.3263],\n        [-0.4351, -2.5059],\n        [ 2.3254, -1.1446]]) \n tensor([ 0.6458,  4.3450,  3.8913, -5.1203,  4.4117, -1.7955,  3.7815,  3.3564,\n        11.8291, 12.7446])\n88 tensor([[-0.5115,  1.7454],\n        [ 0.1885,  0.0839],\n        [-2.3132, -0.0109],\n        [-0.1016,  0.0724],\n        [-0.3010, -0.5194],\n        [-1.5621, -0.2655],\n        [-0.4854,  0.0579],\n        [-1.8395,  1.6287],\n        [ 0.4760, -0.9130],\n        [-1.6567,  0.4283]]) \n tensor([-2.7652,  4.2839, -0.3814,  3.7569,  5.3723,  1.9864,  3.0310, -5.0000,\n         8.2760, -0.5769])\n89 tensor([[-0.4926,  0.4889],\n        [-1.1807,  1.0149],\n        [ 0.2969, -0.6336],\n        [ 0.1846, -0.6704],\n        [ 0.4331,  1.5137],\n        [-0.0584,  1.1291],\n        [-0.3593,  0.8939],\n        [ 0.0477,  0.8664],\n        [ 0.0433, -0.1440],\n        [-0.6958,  0.1678]]) \n tensor([ 1.5456, -1.5969,  6.9628,  6.8513, -0.0847,  0.2452,  0.4535,  1.3331,\n         4.7707,  2.2328])\n90 tensor([[-1.3855, -0.1299],\n        [-1.0420,  0.1457],\n        [-0.6699,  0.1740],\n        [-1.1058,  0.8955],\n        [ 1.2674,  0.0512],\n        [ 0.2398, -0.6540],\n        [-0.4262,  1.2283],\n        [-1.3114,  1.2603],\n        [-1.8799, -0.2493],\n        [-0.5305, -0.2446]]) \n tensor([ 1.8613,  1.6168,  2.2682, -1.0383,  6.5800,  6.9224, -0.8263, -2.7225,\n         1.2897,  3.9731])\n91 tensor([[ 0.7999,  0.4721],\n        [ 0.2421, -0.4888],\n        [-0.3775,  0.1419],\n        [-0.1221, -0.7992],\n        [-0.7029,  1.4235],\n        [-1.0979,  1.1356],\n        [-2.0322, -0.2007],\n        [-0.0970, -1.3306],\n        [ 0.5968,  0.8671],\n        [ 0.0031, -1.2198]]) \n tensor([ 4.1885,  6.3371,  2.9448,  6.6679, -2.0459, -1.8503,  0.8126,  8.5476,\n         2.4605,  8.3513])\n92 tensor([[ 0.3555, -0.1363],\n        [ 0.8267,  0.0208],\n        [ 0.8417,  2.7983],\n        [-0.1289,  0.3365],\n        [ 0.2805,  1.4225],\n        [ 1.0626,  0.0047],\n        [ 0.9565,  0.3097],\n        [ 0.1154, -1.1671],\n        [-0.6935, -0.1034],\n        [ 0.4355,  0.3819]]) \n tensor([ 5.3775,  5.7908, -3.6364,  2.8045, -0.0775,  6.3224,  5.0561,  8.4027,\n         3.1664,  3.7739])\n93 tensor([[-0.8758,  0.3607],\n        [ 1.0727, -0.7106],\n        [ 1.0193, -2.3491],\n        [-0.0527,  0.4385],\n        [-1.4482,  1.3967],\n        [ 0.3313,  0.4917],\n        [ 0.4903, -1.4455],\n        [ 0.1182,  0.2131],\n        [-0.4082, -0.3743],\n        [ 2.3171,  0.9833]]) \n tensor([ 1.2254,  8.7590, 14.2278,  2.6003, -3.4507,  3.2062, 10.1052,  3.6981,\n         4.6387,  5.4820])\n94 tensor([[ 1.1171,  1.1255],\n        [ 0.7796,  0.0490],\n        [ 0.8317, -1.0733],\n        [-0.8592,  1.1121],\n        [ 0.4318,  0.0417],\n        [-1.2187,  1.8025],\n        [-1.2822,  1.7412],\n        [ 0.3064,  0.2855],\n        [ 1.3537,  0.2521],\n        [ 0.1096, -1.8678]]) \n tensor([ 2.5931,  5.5788,  9.5251, -1.2806,  4.9197, -4.3544, -4.2935,  3.8268,\n         6.0614, 10.7764])\n95 tensor([[-0.8089,  1.3296],\n        [ 0.5587, -0.4175],\n        [ 0.1816, -0.7410],\n        [-0.5243,  0.5860],\n        [-0.0734,  0.5363],\n        [ 0.4250,  0.9283],\n        [ 0.2763,  1.3213],\n        [-1.4532,  1.2867],\n        [ 0.1472, -0.2259],\n        [-0.0060, -1.6037]]) \n tensor([-1.9374,  6.7378,  7.0571,  1.1776,  2.2333,  1.9144,  0.2565, -3.0777,\n         5.2796,  9.6616])\n96 tensor([[ 0.0590, -1.1105],\n        [ 0.3769,  0.1020],\n        [ 0.8875, -0.3264],\n        [-1.4460,  0.1514],\n        [ 0.4406,  0.6114],\n        [ 0.8554, -2.2793],\n        [-1.0888, -0.7589],\n        [-0.8928,  2.6791],\n        [-0.4683, -1.3714],\n        [ 0.2697, -0.6403]]) \n tensor([ 8.0842,  4.6130,  7.0682,  0.7946,  3.0091, 13.6673,  4.5986, -6.6967,\n         7.9222,  6.9110])\n97 tensor([[-0.4321,  1.0968],\n        [-1.1815, -0.0326],\n        [ 0.6569,  1.3665],\n        [-0.2478,  1.0610],\n        [ 0.0462, -1.4799],\n        [-1.9488, -0.5901],\n        [-0.0963,  0.8833],\n        [-0.2254,  0.7281],\n        [ 1.5216,  0.6140],\n        [ 0.0935,  1.2764]]) \n tensor([-0.3899,  1.9569,  0.8613,  0.0829,  9.3246,  2.3093,  1.0009,  1.2668,\n         5.1717,  0.0414])\n98 tensor([[-0.1992, -0.5030],\n        [ 1.1169,  0.8471],\n        [-0.2539,  1.2376],\n        [-2.5107,  0.5413],\n        [-1.6188, -0.4221],\n        [ 0.0990,  1.7247],\n        [ 0.8155, -1.8258],\n        [-0.4074, -0.5901],\n        [ 0.9961,  0.6413],\n        [-0.1241,  1.3982]]) \n tensor([ 5.5177,  3.5476, -0.5198, -2.6512,  2.3952, -1.4851, 12.0406,  5.3990,\n         4.0133, -0.7926])\n99 tensor([[ 0.6709, -0.6843],\n        [-2.0472, -1.1578],\n        [ 0.0052, -1.0752],\n        [-0.1224,  0.3966],\n        [-3.0085,  0.0483],\n        [ 0.5210,  0.5552],\n        [-1.3999, -1.3396],\n        [-0.6877, -2.1393],\n        [ 1.7547, -0.6346],\n        [-0.4367, -0.8137]]) \n tensor([ 7.8716,  4.0519,  7.8577,  2.6090, -1.9703,  3.3444,  5.9667, 10.1030,\n         9.8652,  6.1053])\n100 tensor([[ 0.2278,  0.3120],\n        [-2.0233, -0.2171],\n        [-0.0432,  1.3577],\n        [-1.4461, -0.8842],\n        [-0.1210, -0.7479],\n        [ 0.5485, -1.1339],\n        [-0.9953,  1.5139],\n        [ 0.6288, -2.3191],\n        [ 0.8360,  0.1261],\n        [-1.5817, -0.8360]]) \n tensor([ 3.6054,  0.8883, -0.5085,  4.3556,  6.5019,  9.1145, -2.9363, 13.3306,\n         5.4340,  3.8685])\n","name":"stdout"}],"source":"batch_size = 10\ncnt=0\nfor X, y in data_iter(batch_size, features, labels):\n    cnt+=1\n    print(cnt,X, '\\n', y)"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_hj6sxxx","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"1FF819B45B1F44C88012EBB266C10EE8","mdEditEnable":false},"source":"### 初始化模型参数"},{"metadata":{"id":"0A79FDC20EE448F189BC0F9C42FDCEC2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"注意这里的b的大小,与严格的数学不同，这里为$1×1$，我们给$Xw$中的每个元素加上的偏置是一样的，所以偏置参数$b∈R^{1×1}$，基于加法的广播机制，可以完成得到输出$Y=Xw+b$。参数的形状与批量大小没有关系，也正是因为如此，对同一个模型，可以直接训练不同批量大小的数据。"},{"cell_type":"code","execution_count":12,"metadata":{"graffitiCellId":"id_g06bzki","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"6B11AC0E574140CD9C2E722B05D0049D","collapsed":false,"scrolled":false},"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"tensor([0.], requires_grad=True)"},"transient":{},"execution_count":12}],"source":"#初始化，一个赋以随机数，一个赋以零值\nw = torch.tensor(np.random.normal(0, 0.01, (num_inputs, 1)), dtype=torch.float32)\nb = torch.zeros(1, dtype=torch.float32)\n#requires_grad允许该tensor从梯度计算中精细地排除子图，并可以提高效率。\nw.requires_grad_(requires_grad=True)\nb.requires_grad_(requires_grad=True)"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_zvsctyc","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"A91414B8FDF24835A06B6ADFAEC2C15C","mdEditEnable":false},"source":"### 定义模型\n定义用来训练参数的训练模型：\n\n$$\n\\mathrm{price} = w_{\\mathrm{area}} \\cdot \\mathrm{area} + w_{\\mathrm{age}} \\cdot \\mathrm{age} + b\n$$\n\n"},{"cell_type":"code","execution_count":13,"metadata":{"graffitiCellId":"id_l8xu5kf","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"8DFF5BDD78884936899E3CE720BEEE3C","collapsed":false,"scrolled":false},"outputs":[],"source":"def linreg(X, w, b):\n    return torch.mm(X, w) + b#mm是矩阵相乘，mul是矩阵对应位相乘"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_1sta0nq","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"C9B747281D1842C682F2AEB1F38B959D","mdEditEnable":false},"source":"### 定义损失函数\n我们使用的是均方误差损失函数：\n$$\nl^{(i)}(\\mathbf{w}, b) = \\frac{1}{2} \\left(\\hat{y}^{(i)} - y^{(i)}\\right)^2,\n$$\n"},{"cell_type":"code","execution_count":14,"metadata":{"graffitiCellId":"id_r9p6ncn","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"58A55DD7B46842578BEA1A8689456B1A","collapsed":false,"scrolled":false},"outputs":[],"source":"#y_hat的形状是[n, 1]，而y的形状是[n]，两者相减得到的结果的形状是[n, n]，\n#相当于用y_hat的每一个元素分别减去y的所有元素，所以无法得到正确的损失值。\ndef squared_loss(y_hat, y): \n    return (y_hat - y.view(y_hat.size())) ** 2 / 2"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_jm7ie9i","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"0A98B83A8FFD4E84B6EFE8A894643634","mdEditEnable":false},"source":"### 定义优化函数\n在这里优化函数使用的是小批量随机梯度下降：\n\n$$\n(\\mathbf{w},b) \\leftarrow (\\mathbf{w},b) - \\frac{\\eta}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} \\partial_{(\\mathbf{w},b)} l^{(i)}(\\mathbf{w},b)\n$$\n  "},{"cell_type":"code","execution_count":15,"metadata":{"graffitiCellId":"id_e41t41x","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"E9676D1B4F80473B894A4ADA3691D2E0","collapsed":false,"scrolled":false},"outputs":[],"source":"def sgd(params, lr, batch_size): \n    for param in params:\n        param.data -= lr * param.grad / batch_size # ues .data to operate param without gradient track\n                                                   # 这里的param.grad由后续的backward得到"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_0nsokgo","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"B18F2D19AA1140478E2E327ECC97F40F","mdEditEnable":false},"source":"### 训练\n当数据集、模型、损失函数和优化函数定义完了之后就可来准备进行模型的训练了。\n"},{"cell_type":"code","execution_count":19,"metadata":{"graffitiCellId":"id_ht68g0d","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"8C7AA862EE5A4AEAB3CB980F15870D06","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"epoch 1, loss 0.000048\nepoch 2, loss 0.000048\nepoch 3, loss 0.000049\nepoch 4, loss 0.000048\nepoch 5, loss 0.000048\n","name":"stdout"}],"source":"# super parameters init\nlr = 0.03\nnum_epochs = 5\n\nnet = linreg\nloss = squared_loss\n\n# training\nfor epoch in range(num_epochs):  # training repeats num_epochs times\n    # in each epoch, all the samples in dataset will be used once\n    \n    # X is the feature and y is the label of a batch sample\n    for X, y in data_iter(batch_size, features, labels):\n        l = loss(net(X, w, b), y).sum()  \n        \n        # calculate the gradient of batch sample loss，并将具体的梯度更新到具体的变量的属性去\n        l.backward() \n        \n        # using small batch random gradient descent to iter model parameters\n        sgd([w, b], lr, batch_size)  \n        # reset parameter gradient\n        w.grad.data.zero_()\n        b.grad.data.zero_()\n    train_l = loss(net(features, w, b), labels)\n    print('epoch %d, loss %f' % (epoch + 1, train_l.mean().item()))"},{"cell_type":"code","execution_count":20,"metadata":{"graffitiCellId":"id_6t702dg","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"2E791A3F92EF4CCF91E2096630C0E8D9","collapsed":false,"scrolled":false},"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"(tensor([[ 1.9997],\n         [-3.4004]], requires_grad=True),\n [2, -3.4],\n tensor([4.2004], requires_grad=True),\n 4.2)"},"transient":{},"execution_count":20}],"source":"w, true_w, b, true_b"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_pi6pxp6","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"7E8D79B69557446883330AB1E8DE07E2","mdEditEnable":false},"source":"## 线性回归模型使用pytorch的简洁实现\n"},{"cell_type":"code","execution_count":21,"metadata":{"graffitiCellId":"id_sdic11w","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"D5CCF3AE67794558930978F1815C38B9","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"1.3.0\n","name":"stdout"}],"source":"import torch\nfrom torch import nn\nimport numpy as np\ntorch.manual_seed(1)\n\nprint(torch.__version__)\ntorch.set_default_tensor_type('torch.FloatTensor')"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_07nlorv","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"34B9AE6FB3D64DFD83E93D5CEF9EEE65","mdEditEnable":false},"source":"### 生成数据集\n在这里生成数据集跟从零开始的实现中是完全一样的。"},{"cell_type":"code","execution_count":22,"metadata":{"graffitiCellId":"id_k7z5rd0","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"83C2DB9468394624BB4934DBF194A353","collapsed":false,"scrolled":false},"outputs":[],"source":"num_inputs = 2\nnum_examples = 1000\n\ntrue_w = [2, -3.4]\ntrue_b = 4.2\n\nfeatures = torch.tensor(np.random.normal(0, 1, (num_examples, num_inputs)), dtype=torch.float)\nlabels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b\nlabels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()), dtype=torch.float)"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_io6yz0p","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"0FB74CD3CD784A82B2A422E54BB0DEDD","mdEditEnable":false},"source":"### 读取数据集"},{"cell_type":"code","execution_count":23,"metadata":{"graffitiCellId":"id_bxmqh9f","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"8704CA375BF04440839AB16AA995E3AB","collapsed":false,"scrolled":false},"outputs":[],"source":"import torch.utils.data as Data\n\nbatch_size = 10\n\n# combine featues and labels of dataset\ndataset = Data.TensorDataset(features, labels)\n\n# put dataset into DataLoader\ndata_iter = Data.DataLoader(\n    dataset=dataset,            # torch TensorDataset format\n    batch_size=batch_size,      # mini batch size\n    shuffle=True,               # whether shuffle the data or not\n    num_workers=2,              # read data in multithreading，2线程\n)"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_zobpfwu","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"F9085AAAB3BB45E289329A5EA5446848","mdEditEnable":false},"source":"### 定义模型"},{"cell_type":"code","execution_count":34,"metadata":{"graffitiCellId":"id_gxy6vho","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"28DD8C6981314D148B5FD1915639151C","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"LinearNet(\n  (linear): Linear(in_features=2, out_features=1, bias=True)\n)\n","name":"stdout"}],"source":"class LinearNet(nn.Module):\n    def __init__(self, n_feature):\n        super(LinearNet, self).__init__()      # call father function to init \n        self.linear = nn.Linear(n_feature, 1)  # function prototype: `torch.nn.Linear(in_features, out_features, bias=True)`\n\n    def forward(self, x):\n        y = self.linear(x)\n        return y\n    \nnet = LinearNet(num_inputs)\nprint(net)"},{"cell_type":"code","execution_count":35,"metadata":{"graffitiCellId":"id_q5pjt1j","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"56CADFC7B65448BC989411C2C9950816","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"Sequential(\n  (linear): Linear(in_features=2, out_features=1, bias=True)\n)\nLinear(in_features=2, out_features=1, bias=True)\n","name":"stdout"}],"source":"# ways to init a multilayer network\n# method one\nnet = nn.Sequential(\n    nn.Linear(num_inputs, 1)\n    # other layers can be added here\n    )\n\n# method two\nnet = nn.Sequential()\nnet.add_module('linear', nn.Linear(num_inputs, 1))\n# net.add_module ......\n\n# method three\nfrom collections import OrderedDict\nnet = nn.Sequential(OrderedDict([\n          ('linear', nn.Linear(num_inputs, 1))\n          # ......\n        ]))\n\nprint(net)\nprint(net[0])"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_fl434p3","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"1BE602743BCD4C5D948A24212760162D","mdEditEnable":false},"source":"### 初始化模型参数"},{"cell_type":"code","execution_count":36,"metadata":{"graffitiCellId":"id_zdl7vmt","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"025B064D1ED1432385DEE75240A790F6","collapsed":false,"scrolled":false},"outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"Parameter containing:\ntensor([0.], requires_grad=True)"},"transient":{},"execution_count":36}],"source":"from torch.nn import init\n\ninit.normal_(net[0].weight, mean=0.0, std=0.01)\ninit.constant_(net[0].bias, val=0.0)  # or you can use `net[0].bias.data.fill_(0)` to modify it directly"},{"cell_type":"code","execution_count":37,"metadata":{"graffitiCellId":"id_7s9m78k","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"C6A909A717B545E6802264EBD711588D","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"Parameter containing:\ntensor([[-0.0152,  0.0038]], requires_grad=True)\nParameter containing:\ntensor([0.], requires_grad=True)\n","name":"stdout"}],"source":"for param in net.parameters():\n    print(param)"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_l729glu","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"BBFF587F757A4C7EB49AD0D536AD363E","mdEditEnable":false},"source":"### 定义损失函数"},{"cell_type":"code","execution_count":38,"metadata":{"graffitiCellId":"id_or1wah4","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"B721F8DD4811434BB1984B5B2DABC143","collapsed":false,"scrolled":false},"outputs":[],"source":"loss = nn.MSELoss()    # nn built-in squared loss function\n                       # function prototype: `torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')`"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_zyt512e","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"6490FA20F3D4462CB2B98902F694E525","mdEditEnable":false},"source":"### 定义优化函数"},{"cell_type":"code","execution_count":39,"metadata":{"graffitiCellId":"id_pmx4gbq","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"1998CEB53B534F178AC6223011627B0B","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"SGD (\nParameter Group 0\n    dampening: 0\n    lr: 0.03\n    momentum: 0\n    nesterov: False\n    weight_decay: 0\n)\n","name":"stdout"}],"source":"import torch.optim as optim\n\noptimizer = optim.SGD(net.parameters(), lr=0.03)   # built-in random gradient descent function\nprint(optimizer)  # function prototype: `torch.optim.SGD(params, lr=, momentum=0, dampening=0, weight_decay=0, nesterov=False)`"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_n2klgfl","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"090AC5BD4E214B75BD7C4AB9B68720D0","mdEditEnable":false},"source":"### 训练"},{"cell_type":"code","execution_count":40,"metadata":{"graffitiCellId":"id_qj2fl3l","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"A4B0F83F71F94728811A619F1AE74CD2","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"epoch 1, loss: 0.000473\nepoch 2, loss: 0.000104\nepoch 3, loss: 0.000171\n","name":"stdout"}],"source":"num_epochs = 3\nfor epoch in range(1, num_epochs + 1):\n    for X, y in data_iter:\n        output = net(X)\n        l = loss(output, y.view(-1, 1))\n        optimizer.zero_grad() # reset gradient, equal to net.zero_grad()\n        l.backward()\n        optimizer.step()\n    print('epoch %d, loss: %f' % (epoch, l.item()))"},{"cell_type":"code","execution_count":41,"metadata":{"graffitiCellId":"id_ke4hsr4","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"704087439A114181B3A7FE79539127AB","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"[2, -3.4] tensor([[ 1.9997, -3.4003]])\n4.2 tensor([4.2007])\n","name":"stdout"}],"source":"# result comparision\ndense = net[0]\nprint(true_w, dense.weight.data)\nprint(true_b, dense.bias.data)"},{"cell_type":"markdown","metadata":{"graffitiCellId":"id_v7cg0i4","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"A968DC29635C4CDF8394A6F779661DC5","mdEditEnable":false},"source":"## 两种实现方式的比较\n1. 从零开始的实现（推荐用来学习）\n\n   能够更好的理解模型和神经网络底层的原理\n   \n\n2. 使用pytorch的简洁实现\n\n   能够更加快速地完成模型的设计与实现\n   "}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}